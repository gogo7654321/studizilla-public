# AP Statistics Unit 5 Study Guide

:::GUIDE:::
unit::=Unit 5
title::=ğŸ“ˆ Unit 5: Sampling Distributions Complete Guide
desc::=Master sampling distributions, Central Limit Theorem, and the foundation for inference
diff::=Hard
time::=55 minutes
tags::=statistics, sampling distributions, CLT, sample mean, sample proportion
content::=

# ğŸ“ˆ Unit 5: Sampling Distributions

## ğŸ“‹ Unit Overview

Sampling distributions are the bridge between probability and inference! This unit explores how sample statistics vary from sample to sample, laying the foundation for confidence intervals and hypothesis tests! ğŸ“Š

:::TIMELINE:::
id::=history-sampling-distributions
title::=History of Sampling Distributions and the Central Limit Theorem
events::=[
  {"year": "1733", "event": "De Moivre's Discovery", "detail": "Abraham de Moivre discovered that binomial distributions approach a bell curve for large n, the first glimpse of the Central Limit Theorem."},
  {"year": "1809", "event": "Gauss's Error Theory", "detail": "Carl Friedrich Gauss showed that measurement errors follow a normal distribution, establishing the 'Gaussian' curve in scientific measurement."},
  {"year": "1810", "event": "Laplace's General Proof", "detail": "Pierre-Simon Laplace proved a general version of the Central Limit Theorem, showing means of large samples approach normality."},
  {"year": "1901", "event": "Pearson's Sampling Work", "detail": "Karl Pearson studied sampling distributions of statistics, developing the chi-square distribution and correlation coefficient."},
  {"year": "1908", "event": "Student's t-Distribution", "detail": "William Gosset (publishing as 'Student') discovered the t-distribution for small sample inference while working at Guinness Brewery."},
  {"year": "1920", "event": "Fisher's Contributions", "detail": "Ronald Fisher developed sampling distribution theory, showing how sample variance behaves and formalizing degrees of freedom."},
  {"year": "1922", "event": "Lindeberg's CLT Proof", "detail": "Jarl Lindeberg proved the CLT under general conditions, showing why it works for almost any population distribution."},
  {"year": "1935", "event": "Modern Sampling Theory", "detail": "Jerzy Neyman developed the theory of confidence intervals based on sampling distributions, connecting statistics to probability."}
]
:::/TIMELINE:::

### Essential Questions

| Question | Focus |
|----------|-------|
| What is a sampling distribution? | Distribution of a statistic |
| How does sample size matter? | Larger n = less variability |
| What is the Central Limit Theorem? | Distribution becomes normal |
| How does sampling distribution of pÌ‚ behave? | Mean, spread, shape |
| How does sampling distribution of xÌ„ behave? | Mean, spread, shape |

### Key Concepts

| Concept | Description |
|---------|-------------|
| **Sampling distribution** | Distribution of sample statistic |
| **Standard error** | Standard deviation of statistic |
| **Central Limit Theorem** | Large n â†’ normal distribution |
| **Unbiased estimator** | Mean equals parameter |
| **Variability** | Decreases with larger n |

---

## ğŸ“Š What is a Sampling Distribution?

### Definition

| Concept | Description |
|---------|-------------|
| **Sampling distribution** | Distribution of all possible values of a statistic |
| **From** | All possible samples of same size |
| **Key idea** | Statistics vary from sample to sample |

### Important Distinction

| Term | Description |
|------|-------------|
| **Population distribution** | Distribution of individual values |
| **Sample distribution** | Distribution of data in one sample |
| **Sampling distribution** | Distribution of a statistic |

### Why Sampling Distributions Matter

| Purpose | Description |
|---------|-------------|
| **Inference** | Basis for confidence intervals |
| **Probability** | Calculate likelihood of results |
| **Predict variability** | How much statistics vary |

---

## ğŸ¯ Sampling Distribution of pÌ‚ (Proportions)

### Setup

| Symbol | Meaning |
|--------|---------|
| **p** | Population proportion (parameter) |
| **pÌ‚** | Sample proportion (statistic) |
| **n** | Sample size |

### Mean of pÌ‚

| Formula | Î¼_pÌ‚ = p |
|---------|---------|
| **Meaning** | pÌ‚ is unbiased estimator of p |
| **On average** | pÌ‚ equals p |

### Standard Deviation of pÌ‚

| Formula | |
|---------|--|
| **Ïƒ_pÌ‚** | = âˆš[p(1-p)/n] |
| **Decreases as** | n increases |

### Condition for Standard Deviation Formula

| Condition | |
|-----------|--|
| **10% condition** | n â‰¤ 10% of population |
| **Why** | Without replacement needs this |

### Shape of Sampling Distribution

| Condition for Normality | |
|-------------------------|--|
| **Large counts** | np â‰¥ 10 AND n(1-p) â‰¥ 10 |
| **If met** | Approximately normal |

### Summary: Sampling Distribution of pÌ‚

| Property | Value |
|----------|-------|
| **Mean** | Î¼_pÌ‚ = p |
| **Std Dev** | Ïƒ_pÌ‚ = âˆš[p(1-p)/n] |
| **Shape** | Normal if np â‰¥ 10 and n(1-p) â‰¥ 10 |

---

## ğŸ“ˆ Using the Sampling Distribution of pÌ‚

### Finding Probability of pÌ‚

| Step | Action |
|------|--------|
| **1** | Check conditions (10%, large counts) |
| **2** | Calculate Î¼_pÌ‚ = p |
| **3** | Calculate Ïƒ_pÌ‚ = âˆš[p(1-p)/n] |
| **4** | Use normalcdf |

### Z-Score for pÌ‚

| Formula | |
|---------|--|
| **z** | = (pÌ‚ - p) / âˆš[p(1-p)/n] |

### Example

| Given | |
|-------|--|
| **p = 0.6** | Population proportion |
| **n = 100** | Sample size |
| **Find P(pÌ‚ < 0.55)** | |

| Step | Calculation |
|------|-------------|
| **Î¼_pÌ‚** | = 0.6 |
| **Ïƒ_pÌ‚** | = âˆš[0.6(0.4)/100] = 0.049 |
| **z** | = (0.55 - 0.6)/0.049 = -1.02 |
| **P(pÌ‚ < 0.55)** | = normalcdf(-âˆ, -1.02) â‰ˆ 0.154 |

---

## ğŸ“Š Sampling Distribution of xÌ„ (Means)

### Setup

| Symbol | Meaning |
|--------|---------|
| **Î¼** | Population mean (parameter) |
| **xÌ„** | Sample mean (statistic) |
| **Ïƒ** | Population standard deviation |
| **n** | Sample size |

### Mean of xÌ„

| Formula | Î¼_xÌ„ = Î¼ |
|---------|---------|
| **Meaning** | xÌ„ is unbiased estimator of Î¼ |
| **On average** | xÌ„ equals Î¼ |

### Standard Deviation of xÌ„

| Formula | |
|---------|--|
| **Ïƒ_xÌ„** | = Ïƒ / âˆšn |
| **Called** | Standard error of the mean |
| **Decreases as** | n increases |

### 10% Condition

| Condition | |
|-----------|--|
| **n â‰¤ 10% of population** | For sampling without replacement |
| **If violated** | Formula needs adjustment |

---

## ğŸ”” Central Limit Theorem (CLT)

### The Theorem

| Statement | |
|-----------|--|
| **For large n** | Sampling distribution of xÌ„ is approximately normal |
| **Regardless of** | Population distribution shape |
| **How large?** | n â‰¥ 30 (rule of thumb) |

### When is n "Large Enough"?

| Population Shape | Required n |
|------------------|------------|
| **Normal** | Any n |
| **Slightly skewed** | n â‰¥ 15 |
| **Strongly skewed** | n â‰¥ 30 or more |
| **Outliers present** | Larger n needed |

### Why CLT Matters

| Importance | Description |
|------------|-------------|
| **Powerful** | Works for any population |
| **Foundation** | For inference procedures |
| **Universal** | Explains many phenomena |

---

## ğŸ“ Summary: Sampling Distribution of xÌ„

### Three Properties

| Property | Value/Condition |
|----------|-----------------|
| **Mean** | Î¼_xÌ„ = Î¼ |
| **Std Dev** | Ïƒ_xÌ„ = Ïƒ/âˆšn (10% condition) |
| **Shape** | Normal if population normal OR n â‰¥ 30 |

### Comparison

| n Increases | Effect |
|-------------|--------|
| **Mean** | Stays same (Î¼) |
| **Standard error** | Decreases (Ïƒ/âˆšn) |
| **Shape** | Becomes more normal |

---

## ğŸ“ˆ Using the Sampling Distribution of xÌ„

### Finding Probability of xÌ„

| Step | Action |
|------|--------|
| **1** | Check conditions (normal pop or n â‰¥ 30, 10%) |
| **2** | Calculate Î¼_xÌ„ = Î¼ |
| **3** | Calculate Ïƒ_xÌ„ = Ïƒ/âˆšn |
| **4** | Use normalcdf |

### Z-Score for xÌ„

| Formula | |
|---------|--|
| **z** | = (xÌ„ - Î¼) / (Ïƒ/âˆšn) |

### Example

| Given | |
|-------|--|
| **Î¼ = 500** | Population mean |
| **Ïƒ = 100** | Population std dev |
| **n = 25** | Sample size |
| **Find P(xÌ„ > 520)** | |

| Step | Calculation |
|------|-------------|
| **Î¼_xÌ„** | = 500 |
| **Ïƒ_xÌ„** | = 100/âˆš25 = 20 |
| **z** | = (520 - 500)/20 = 1.00 |
| **P(xÌ„ > 520)** | = 1 - normalcdf(-âˆ, 1) â‰ˆ 0.159 |

---

## âš ï¸ Common Errors

### Individual vs. Sample Mean

| Question About | Use |
|----------------|-----|
| **One individual** | Ïƒ (population std dev) |
| **Sample mean** | Ïƒ/âˆšn (standard error) |

### Example Distinction

| Scenario | Standard Deviation |
|----------|-------------------|
| **P(one score > 520)** | Ïƒ = 100 |
| **P(mean of 25 > 520)** | Ïƒ/âˆšn = 20 |

### The Sample Mean is Less Variable

| Why | Explanation |
|-----|-------------|
| **Averaging** | Extreme values cancel |
| **Larger n** | More cancellation |
| **Result** | xÌ„ closer to Î¼ than individuals |

---

## ğŸ”„ Effect of Sample Size

### On Standard Error

| n | Ïƒ_xÌ„ = Ïƒ/âˆšn | Effect |
|---|-------------|--------|
| **4** | Ïƒ/2 | Half of Ïƒ |
| **9** | Ïƒ/3 | Third of Ïƒ |
| **25** | Ïƒ/5 | Fifth of Ïƒ |
| **100** | Ïƒ/10 | Tenth of Ïƒ |

### Quadrupling Rule

| To Cut Error in Half | |
|---------------------|--|
| **Quadruple n** | âˆš4 = 2 in denominator |
| **Example** | n: 25 â†’ 100 halves Ïƒ_xÌ„ |

---

## ğŸ“Š Sampling Distribution of Difference

### Difference of Proportions (pÌ‚â‚ - pÌ‚â‚‚)

| Property | Formula |
|----------|---------|
| **Mean** | Î¼ = pâ‚ - pâ‚‚ |
| **Std Dev** | Ïƒ = âˆš[pâ‚(1-pâ‚)/nâ‚ + pâ‚‚(1-pâ‚‚)/nâ‚‚] |
| **Shape** | Normal if large counts for both |

### Difference of Means (xÌ„â‚ - xÌ„â‚‚)

| Property | Formula |
|----------|---------|
| **Mean** | Î¼ = Î¼â‚ - Î¼â‚‚ |
| **Std Dev** | Ïƒ = âˆš[Ïƒâ‚Â²/nâ‚ + Ïƒâ‚‚Â²/nâ‚‚] |
| **Shape** | Normal if both populations normal or large n |

---

## ğŸ“ Conditions Summary

### For Proportions (pÌ‚)

| Condition | Check |
|-----------|-------|
| **Random** | Random sample or assignment |
| **10%** | n â‰¤ 10% of population |
| **Large counts** | np â‰¥ 10 and n(1-p) â‰¥ 10 |

### For Means (xÌ„)

| Condition | Check |
|-----------|-------|
| **Random** | Random sample or assignment |
| **10%** | n â‰¤ 10% of population |
| **Normal/Large sample** | Population normal OR n â‰¥ 30 |

---

## ğŸ“ˆ Visualizing Sampling Distributions

### As n Increases

| Property | Change |
|----------|--------|
| **Center** | Stays at parameter |
| **Spread** | Decreases |
| **Shape** | Becomes more normal |

### Graph Comparison

| Small n | Large n |
|---------|---------|
| Wide distribution | Narrow distribution |
| May not be normal | Approximately normal |
| More variability | Less variability |

---

## ğŸ” Bias vs. Variability

### Bias

| Concept | Description |
|---------|-------------|
| **Definition** | Systematic error |
| **Center off** | Mean â‰  parameter |
| **Caused by** | Bad sampling method |
| **Fixed by** | Better design |

### Variability

| Concept | Description |
|---------|-------------|
| **Definition** | Spread of sampling distribution |
| **High variability** | Wide distribution |
| **Reduced by** | Larger sample size |

### Ideal

| Goal | How |
|------|-----|
| **Low bias** | Random sampling |
| **Low variability** | Large sample size |

---

## ğŸ“ Key Terms Glossary

| Term | Definition |
|------|------------|
| **Sampling distribution** | Distribution of statistic from all samples |
| **Standard error** | Standard deviation of a statistic |
| **Unbiased** | Mean of statistic equals parameter |
| **Central Limit Theorem** | Large n â†’ normal distribution |
| **10% condition** | Sample â‰¤ 10% of population |
| **Large counts** | np â‰¥ 10 and n(1-p) â‰¥ 10 |
| **Variability** | Spread of sampling distribution |
| **Bias** | Systematic deviation from parameter |

---

## ğŸ¯ AP Exam Strategies

### Free Response Tips

| Task | How to Answer |
|------|---------------|
| **Describe sampling distribution** | Mean, std dev, shape |
| **Check conditions** | State and verify each |
| **Calculate probability** | Show work with formula |
| **Explain CLT** | Large n â†’ approx. normal |

### Common Mistakes

| Mistake | Correction |
|---------|------------|
| **Use Ïƒ instead of Ïƒ/âˆšn** | For means, divide by âˆšn |
| **Skip conditions** | Always state and check |
| **Normal without justification** | Need normal pop or n â‰¥ 30 |
| **Confuse p and pÌ‚** | p = parameter, pÌ‚ = statistic |

### Key Formulas

| Statistic | Mean | Std Dev | Normal If |
|-----------|------|---------|-----------|
| **pÌ‚** | p | âˆš[p(1-p)/n] | np â‰¥ 10, n(1-p) â‰¥ 10 |
| **xÌ„** | Î¼ | Ïƒ/âˆšn | Normal pop or n â‰¥ 30 |

---

**Good luck on your AP Statistics exam! ğŸ€ğŸ“ˆğŸ“Š**

Remember: The Central Limit Theorem is incredibly powerful - no matter the population shape, large samples give approximately normal sampling distributions!

---

## ğŸ† Famous Statisticians in Sampling Theory

| Statistician | Contribution | Era |
|--------------|--------------|-----|
| **Abraham de Moivre** | First discovered normal approximation | 1733 |
| **Pierre-Simon Laplace** | Proved Central Limit Theorem | 1810 |
| **Carl Friedrich Gauss** | Normal distribution (Gaussian curve) | 1809 |
| **William Gosset (Student)** | t-distribution for small samples | 1908 |
| **Ronald A. Fisher** | Sampling distribution theory | 1920s |
| **Jerzy Neyman** | Confidence interval framework | 1930s |

---

## ğŸ“Š Worked Examples: Sampling Distribution of pÌ‚

### Example 1: Check Conditions and Find Probability

**Problem:** A large company claims 80% of customers are satisfied. In a random sample of 200 customers, what is the probability that less than 75% are satisfied?

**Check Conditions:**
1. **Random:** Random sample stated âœ“
2. **10%:** 200 is less than 10% of all customers (assuming large company) âœ“
3. **Large counts:** np = 200(0.80) = 160 â‰¥ 10 âœ“
   n(1-p) = 200(0.20) = 40 â‰¥ 10 âœ“

**Sampling Distribution:**
- Mean: $\mu_{\hat{p}} = p = 0.80$
- Standard deviation: $\sigma_{\hat{p}} = \sqrt{\frac{p(1-p)}{n}} = \sqrt{\frac{0.80(0.20)}{200}} = \sqrt{0.0008} = 0.0283$
- Shape: Approximately normal (conditions met)

**Calculate:**
$$z = \frac{0.75 - 0.80}{0.0283} = \frac{-0.05}{0.0283} = -1.77$$

$$P(\hat{p} < 0.75) = P(Z < -1.77) = 0.0384$$

**TI-84:** normalcdf(-1E99, 0.75, 0.80, 0.0283) = 0.0384

**Interpretation:** If truly 80% are satisfied, there's only a 3.84% chance of getting a sample proportion below 75%. This would be surprising evidence against the company's claim.

### Example 2: Finding Critical Values

**Problem:** Using the same scenario, what sample proportion would be so low that only 5% of samples would have a proportion that low or lower?

**Solution:**
Find $\hat{p}$ such that $P(\hat{p} < x) = 0.05$

From standard normal: z = -1.645

$$\hat{p} = \mu_{\hat{p}} + z \cdot \sigma_{\hat{p}} = 0.80 + (-1.645)(0.0283) = 0.80 - 0.0465 = 0.7535$$

**TI-84:** invNorm(0.05, 0.80, 0.0283) = 0.7534

---

## ğŸ“ˆ Worked Examples: Sampling Distribution of xÌ„

### Example 1: Normal Population

**Problem:** IQ scores are normally distributed with Î¼ = 100 and Ïƒ = 15. A random sample of 25 people is selected. What is the probability that the sample mean IQ exceeds 105?

**Check Conditions:**
1. **Random:** Stated âœ“
2. **10%:** 25 < 10% of all people âœ“
3. **Normal:** Population is normal (stated) âœ“

**Sampling Distribution:**
- Mean: $\mu_{\bar{x}} = \mu = 100$
- Standard deviation: $\sigma_{\bar{x}} = \frac{\sigma}{\sqrt{n}} = \frac{15}{\sqrt{25}} = \frac{15}{5} = 3$
- Shape: Normal (population is normal)

**Calculate:**
$$z = \frac{105 - 100}{3} = \frac{5}{3} = 1.67$$

$$P(\bar{x} > 105) = P(Z > 1.67) = 1 - 0.9525 = 0.0475$$

**TI-84:** normalcdf(105, 1E99, 100, 3) = 0.0478

### Example 2: Non-Normal Population (CLT Application)

**Problem:** A company's call times are right-skewed with Î¼ = 8 minutes and Ïƒ = 4 minutes. For a random sample of 50 calls, find P(xÌ„ < 7 minutes).

**Check Conditions:**
1. **Random:** Stated âœ“
2. **10%:** 50 < 10% of all calls âœ“
3. **Normal/Large sample:** n = 50 â‰¥ 30, so CLT applies âœ“

**Sampling Distribution:**
- Mean: $\mu_{\bar{x}} = 8$
- Standard deviation: $\sigma_{\bar{x}} = \frac{4}{\sqrt{50}} = \frac{4}{7.07} = 0.566$
- Shape: Approximately normal by CLT

**Calculate:**
$$z = \frac{7 - 8}{0.566} = \frac{-1}{0.566} = -1.77$$

$$P(\bar{x} < 7) = P(Z < -1.77) = 0.0384$$

### Example 3: Individual vs. Sample Mean

**Problem:** Heights of adult women have Î¼ = 64.5 inches and Ïƒ = 2.5 inches.

a) What is P(one randomly selected woman > 67 inches)?
b) What is P(sample mean of 36 women > 67 inches)?

**Solution:**

**Part a) Individual:**
$$z = \frac{67 - 64.5}{2.5} = 1.00$$
$$P(X > 67) = 0.1587$$

**Part b) Sample Mean:**
$$\sigma_{\bar{x}} = \frac{2.5}{\sqrt{36}} = 0.417$$
$$z = \frac{67 - 64.5}{0.417} = 6.00$$
$$P(\bar{x} > 67) \approx 0$$

**Key Insight:** It's common for an individual to be 67+ inches, but virtually impossible for a sample mean of 36 women to exceed 67 inches. This shows the power of averaging!

---

## ğŸ“ Visualizing the Central Limit Theorem

```
Population Distribution (Right-Skewed):
â–
â–â–ˆ
â–â–ˆâ–ˆ
â–â–ˆâ–ˆâ–ˆ
â–â–ˆâ–ˆâ–ˆâ–ˆâ–Œ
â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œâ–Œâ–Œ
â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œâ–Œâ–Œâ–Œâ–Œâ–Œ
â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œâ–Œâ–Œâ–Œâ–Œâ–Œâ–Œâ–Œâ–Œ

Sampling Distribution of xÌ„ (n = 30):
         â–â–Œ
        â–â–ˆâ–ˆâ–Œ
       â–â–ˆâ–ˆâ–ˆâ–ˆâ–Œ
      â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ
     â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ
    â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ
   â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ
  â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ
 â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ
â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ

Key observations:
â€¢ Same center (mean stays at Î¼)
â€¢ Much narrower spread (Ïƒ/âˆšn)
â€¢ Approximately normal shape (CLT!)
```

---

## ğŸ”¢ Effect of Sample Size: Detailed Analysis

| Sample Size (n) | Standard Error (Ïƒ/âˆšn) | Width Relative to Ïƒ |
|-----------------|----------------------|---------------------|
| 1 | Ïƒ/1 = Ïƒ | 100% |
| 4 | Ïƒ/2 = 0.5Ïƒ | 50% |
| 9 | Ïƒ/3 = 0.33Ïƒ | 33% |
| 16 | Ïƒ/4 = 0.25Ïƒ | 25% |
| 25 | Ïƒ/5 = 0.2Ïƒ | 20% |
| 36 | Ïƒ/6 = 0.167Ïƒ | 17% |
| 100 | Ïƒ/10 = 0.1Ïƒ | 10% |
| 400 | Ïƒ/20 = 0.05Ïƒ | 5% |

**Important Pattern:** To halve the standard error, you must QUADRUPLE the sample size!

---

## ğŸ“Š Difference of Two Proportions: Worked Example

**Problem:** In a poll, 65% of 400 adults (sample 1) favor a policy, and 58% of 350 adults (sample 2) favor it. Assuming these are the true proportions, what is P(pÌ‚â‚ - pÌ‚â‚‚ > 0.10)?

**Check Conditions:**
- Both samples random âœ“
- Both satisfy 10% condition âœ“
- Large counts for both: 400(0.65) = 260, 400(0.35) = 140, 350(0.58) = 203, 350(0.42) = 147 âœ“

**Sampling Distribution of pÌ‚â‚ - pÌ‚â‚‚:**

Mean: $\mu = p_1 - p_2 = 0.65 - 0.58 = 0.07$

Standard Deviation: 
$$\sigma = \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}} = \sqrt{\frac{0.65(0.35)}{400} + \frac{0.58(0.42)}{350}}$$
$$= \sqrt{0.000569 + 0.000696} = \sqrt{0.001265} = 0.0356$$

**Calculate:**
$$z = \frac{0.10 - 0.07}{0.0356} = 0.84$$

$$P(\hat{p}_1 - \hat{p}_2 > 0.10) = P(Z > 0.84) = 0.2005$$

---

## ğŸ“ˆ Difference of Two Means: Worked Example

**Problem:** Factory A produces bolts with Î¼â‚ = 10.0 mm, Ïƒâ‚ = 0.2 mm. Factory B produces bolts with Î¼â‚‚ = 10.1 mm, Ïƒâ‚‚ = 0.3 mm. If 40 bolts are sampled from each, what is P(xÌ„â‚ > xÌ„â‚‚)?

**Sampling Distribution of xÌ„â‚ - xÌ„â‚‚:**

Mean: $\mu = \mu_1 - \mu_2 = 10.0 - 10.1 = -0.1$

Standard Deviation:
$$\sigma = \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}} = \sqrt{\frac{0.04}{40} + \frac{0.09}{40}} = \sqrt{0.00325} = 0.057$$

**Find P(xÌ„â‚ - xÌ„â‚‚ > 0):**
$$z = \frac{0 - (-0.1)}{0.057} = \frac{0.1}{0.057} = 1.75$$

$$P(\bar{x}_1 > \bar{x}_2) = P(Z > 1.75) = 0.0401$$

---

## ğŸ¯ Conditions Checklist for AP Exam

### For Proportions (pÌ‚)

| Condition | How to Check | How to Write |
|-----------|--------------|--------------|
| **Random** | SRS or random assignment | "The sample is a random sample of [population]" |
| **10%** | n â‰¤ 0.10N | "200 is less than 10% of all [population]" |
| **Large Counts** | np â‰¥ 10 AND n(1-p) â‰¥ 10 | "np = 200(0.8) = 160 â‰¥ 10 and n(1-p) = 200(0.2) = 40 â‰¥ 10" |

### For Means (xÌ„)

| Condition | How to Check | How to Write |
|-----------|--------------|--------------|
| **Random** | SRS or random assignment | "The sample is a random sample of [population]" |
| **10%** | n â‰¤ 0.10N | "50 is less than 10% of all [population]" |
| **Normal/Large Sample** | Pop normal OR n â‰¥ 30 | "n = 50 â‰¥ 30, so CLT ensures approximately normal distribution" |

---

## âš ï¸ Common AP Exam Mistakes

| Mistake | Why It's Wrong | Correct Approach |
|---------|----------------|------------------|
| Using Ïƒ instead of Ïƒ/âˆšn | For sample means, standard error is Ïƒ/âˆšn | Always divide Ïƒ by âˆšn for means |
| Checking npÌ‚ instead of np | Conditions use PARAMETER p, not statistic pÌ‚ | Use claimed/true p value |
| Saying "population is normal" without evidence | Need justification | Check graph or state n â‰¥ 30 |
| Confusing p with pÌ‚ | p = parameter (true), pÌ‚ = statistic (sample) | p is what we assume, pÌ‚ is what we observe |
| Skipping condition checks | Must show all conditions | State each condition with verification |

---

## ğŸ“Š TI-84 Calculator Commands

| Task | Command | Example |
|------|---------|---------|
| P(X < value) for normal | normalcdf(-1E99, value, Î¼, Ïƒ) | normalcdf(-1E99, 0.75, 0.80, 0.0283) |
| P(X > value) for normal | normalcdf(value, 1E99, Î¼, Ïƒ) | normalcdf(105, 1E99, 100, 3) |
| P(a < X < b) for normal | normalcdf(a, b, Î¼, Ïƒ) | normalcdf(97, 103, 100, 3) |
| Find value from percentile | invNorm(area, Î¼, Ïƒ) | invNorm(0.05, 0.80, 0.0283) |

---

## ğŸ”— Connection to Later Units

| Unit | Connection to Sampling Distributions |
|------|-------------------------------------|
| **Unit 6** | CI and tests for proportions use sampling distribution of pÌ‚ |
| **Unit 7** | CI and tests for means use sampling distribution of xÌ„ |
| **Unit 8** | Chi-square based on sampling distribution of test statistic |
| **Unit 9** | Regression inference uses sampling distribution of slope b |

**The Big Picture:** Understanding sampling distributions is ESSENTIAL because ALL of statistical inference is based on knowing how sample statistics behave when we take repeated samples!
